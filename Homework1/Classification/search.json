[{"dropout": 0.15627944687333778, "learning_rate": 0.0019430005939618578, "optimizer": "adam", "regularization": 0.0015299851163588986, "loss": 0.17072755098342896}, {"dropout": 0.15627944687333778, "learning_rate": 0.0025332856553993434, "optimizer": "sgd", "regularization": 0.011967256598720728, "loss": 0.21884337067604065}, {"dropout": 0.032388042815438556, "learning_rate": 0.0019430005939618578, "optimizer": "adam", "regularization": 0.011552045117952053, "loss": 0.2897517681121826}, {"dropout": 0.4629448333659678, "learning_rate": 0.000739665246798381, "optimizer": "adam", "regularization": 0.056745115911192356, "loss": 2.3014872074127197}, {"dropout": 0.4629448333659678, "learning_rate": 0.007477285521397046, "optimizer": "sgd", "regularization": 0.0052383790521212305, "loss": 0.1615450233221054}, {"dropout": 0.4629448333659678, "learning_rate": 0.001451835994315487, "optimizer": "sgd", "regularization": 0.011552045117952053, "loss": 0.20962423086166382}, {"dropout": 0.4629448333659678, "learning_rate": 0.00013837712686067848, "optimizer": "sgd", "regularization": 0.028140792726320262, "loss": 2.2987265586853027}, {"dropout": 0.4629448333659678, "learning_rate": 0.0025332856553993434, "optimizer": "adam", "regularization": 0.04415169700933284, "loss": 2.301250696182251}, {"dropout": 0.15627944687333778, "learning_rate": 0.0019430005939618578, "optimizer": "adam", "regularization": 0.028140792726320262, "loss": 2.301572561264038}, {"dropout": 0.46590455371383516, "learning_rate": 0.007477285521397046, "optimizer": "sgd", "regularization": 0.011967256598720728, "loss": 0.24176423251628876}, {"dropout": 0.1059012491757188, "learning_rate": 0.00013837712686067848, "optimizer": "adam", "regularization": 0.06665729228176971, "loss": 2.3019051551818848}, {"dropout": 0.42766077369940675, "learning_rate": 0.001451835994315487, "optimizer": "adam", "regularization": 0.0052383790521212305, "loss": 0.2210206389427185}, {"dropout": 0.11531227712090703, "learning_rate": 0.0025332856553993434, "optimizer": "sgd", "regularization": 0.056745115911192356, "loss": 2.3013968467712402}, {"dropout": 0.45808149818667443, "learning_rate": 0.000739665246798381, "optimizer": "sgd", "regularization": 0.056745115911192356, "loss": 2.3007373809814453}, {"dropout": 0.032388042815438556, "learning_rate": 0.006399191374459892, "optimizer": "adam", "regularization": 0.056745115911192356, "loss": 2.301786184310913}, {"dropout": 0.42766077369940675, "learning_rate": 0.0025332856553993434, "optimizer": "adam", "regularization": 0.04415169700933284, "loss": 2.3013734817504883}, {"dropout": 0.45808149818667443, "learning_rate": 0.000739665246798381, "optimizer": "adam", "regularization": 0.0032969975496218145, "loss": 0.16802436113357544}, {"dropout": 0.032388042815438556, "learning_rate": 0.0019430005939618578, "optimizer": "sgd", "regularization": 0.0020949035429595688, "loss": 0.11155471950769424}, {"dropout": 0.4629448333659678, "learning_rate": 0.00485059714196399, "optimizer": "adam", "regularization": 0.0032969975496218145, "loss": 0.436188668012619}, {"dropout": 0.11531227712090703, "learning_rate": 0.006399191374459892, "optimizer": "sgd", "regularization": 0.0052383790521212305, "loss": 0.16345369815826416}]