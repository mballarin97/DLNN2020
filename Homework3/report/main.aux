\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\abx@aux@refcontext{none/global//global/global}
\abx@aux@cite{gym}
\abx@aux@segm{0}{0}{gym}
\babel@aux{english}{}
\newlabel{sec:int}{{1}{1}{Introduction}{section.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction }{1}{section.1}\protected@file@percent }
\newlabel{sec:cart}{{2}{1}{Cartpole}{section.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2}Cartpole }{1}{section.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Methods}{1}{subsection.2.1}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Neural network for the evaluation of the $Q$-values given the state.\relax }}{2}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:dqnet}{{1}{2}{Neural network for the evaluation of the $Q$-values given the state.\relax }{figure.caption.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Results}{3}{subsection.2.2}\protected@file@percent }
\newlabel{sec:pixels}{{3}{3}{Cartpole with pixels}{section.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3}Cartpole with pixels }{3}{section.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Methods}{3}{subsection.3.1}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Architecture of the convolutional neural network used as agent.\relax }}{4}{figure.caption.2}\protected@file@percent }
\newlabel{fig:conv}{{2}{4}{Architecture of the convolutional neural network used as agent.\relax }{figure.caption.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Results}{4}{subsection.3.2}\protected@file@percent }
\newlabel{sec:LunLand}{{4}{4}{Lunar Landing}{section.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4}Lunar Landing }{4}{section.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Methods}{4}{subsection.4.1}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Architecture of the network used in the Lunar Lander environment.\relax }}{5}{figure.caption.3}\protected@file@percent }
\newlabel{fig:lun_arc}{{3}{5}{Architecture of the network used in the Lunar Lander environment.\relax }{figure.caption.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Results}{5}{subsection.4.2}\protected@file@percent }
\abx@aux@refcontextdefaultsdone
\abx@aux@defaultrefcontext{0}{gym}{none/global//global/global}
\newlabel{sec:app}{{5}{6}{Appendix}{section.5}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5}Appendix }{6}{section.5}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Example of the rendered environment for the cartpole. We can notice the cart in black, the pole in brown and the moving rail represented by black line.\relax }}{6}{figure.caption.5}\protected@file@percent }
\newlabel{fig:Cart}{{4}{6}{Example of the rendered environment for the cartpole. We can notice the cart in black, the pole in brown and the moving rail represented by black line.\relax }{figure.caption.5}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Hyperparameters search, where the color of the line is proportional to the first\_solved field. We stress that the best set of trials are the one with lowest first\_solved.\relax }}{6}{figure.caption.6}\protected@file@percent }
\newlabel{fig:hyper}{{5}{6}{Hyperparameters search, where the color of the line is proportional to the first\_solved field. We stress that the best set of trials are the one with lowest first\_solved.\relax }{figure.caption.6}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces In red the exploration profile and in blue the training score for the best performing hyperparameter set. The training score increases immediately after the temperature approaches $0$.\relax }}{7}{figure.caption.7}\protected@file@percent }
\newlabel{fig:best_cart}{{6}{7}{In red the exploration profile and in blue the training score for the best performing hyperparameter set. The training score increases immediately after the temperature approaches $0$.\relax }{figure.caption.7}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces In red the exploration profile and in blue the training score for a well performing hyperparameter set. We see that, even if we have an increase in the temperature towards the end, the agent still performs a very good score.\relax }}{7}{figure.caption.8}\protected@file@percent }
\newlabel{fig:norm_cart}{{7}{7}{In red the exploration profile and in blue the training score for a well performing hyperparameter set. We see that, even if we have an increase in the temperature towards the end, the agent still performs a very good score.\relax }{figure.caption.8}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces In red the exploration profile and in blue the training score for a hyperparameter set not able to solve the environment. The training score stabilizes around $100$, which is far under the maximum score.\relax }}{8}{figure.caption.9}\protected@file@percent }
\newlabel{fig:bad_cart}{{8}{8}{In red the exploration profile and in blue the training score for a hyperparameter set not able to solve the environment. The training score stabilizes around $100$, which is far under the maximum score.\relax }{figure.caption.9}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Samples of the image given as an input to the network. We observe that they are cropped and putted in a grayscale.\relax }}{8}{figure.caption.10}\protected@file@percent }
\newlabel{fig:image}{{9}{8}{Samples of the image given as an input to the network. We observe that they are cropped and putted in a grayscale.\relax }{figure.caption.10}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces In red the exploration profile and in blue the training score before the application of the supervised network for the learning from pixels. The blue curve ends prematurely due to a memory leak. We can see that, even if the environment is not solved, the agent learns a strategy, since the average score increases significantly.\relax }}{8}{figure.caption.11}\protected@file@percent }
\newlabel{fig:bef_trick}{{10}{8}{In red the exploration profile and in blue the training score before the application of the supervised network for the learning from pixels. The blue curve ends prematurely due to a memory leak. We can see that, even if the environment is not solved, the agent learns a strategy, since the average score increases significantly.\relax }{figure.caption.11}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces In red the exploration profile and in blue the training score before the application of the supervised network for the learning from pixels. The score is lower than the one in Figure \ref  {fig:bef_trick}. This is due to problems in the supervised learning task, such as the low number of training samples.\relax }}{9}{figure.caption.12}\protected@file@percent }
\newlabel{fig:aft_trick}{{11}{9}{In red the exploration profile and in blue the training score before the application of the supervised network for the learning from pixels. The score is lower than the one in Figure \ref {fig:bef_trick}. This is due to problems in the supervised learning task, such as the low number of training samples.\relax }{figure.caption.12}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces In red the exploration profile and in blue the training score, starting the learning from the supervised network without freezing the weights. The score is higher than the one in Figure \ref  {fig:bef_trick}, but it is really unstable and it so not a reliable improvement.\relax }}{9}{figure.caption.13}\protected@file@percent }
\newlabel{fig:nofreeze}{{12}{9}{In red the exploration profile and in blue the training score, starting the learning from the supervised network without freezing the weights. The score is higher than the one in Figure \ref {fig:bef_trick}, but it is really unstable and it so not a reliable improvement.\relax }{figure.caption.13}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Example of the rendered environment for the lunar lander. We can notice the landing space delimited by the flags and the lander in violet on the top center.\relax }}{10}{figure.caption.14}\protected@file@percent }
\newlabel{fig:Lunar}{{13}{10}{Example of the rendered environment for the lunar lander. We can notice the landing space delimited by the flags and the lander in violet on the top center.\relax }{figure.caption.14}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces In red the exploration profile and in blue the training score for the LunarLander environment. The environment is considered solved with a score of $200$, which is reached at around $800$ iterations. We can also observe that the score increases significantly at $600$ iterations after a plateau, in correspondence to the end of the gaussian addition.\relax }}{10}{figure.caption.15}\protected@file@percent }
\newlabel{fig:score_lunar}{{14}{10}{In red the exploration profile and in blue the training score for the LunarLander environment. The environment is considered solved with a score of $200$, which is reached at around $800$ iterations. We can also observe that the score increases significantly at $600$ iterations after a plateau, in correspondence to the end of the gaussian addition.\relax }{figure.caption.15}{}}
\gdef \@abspage@last{10}
