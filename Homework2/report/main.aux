\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\abx@aux@refcontext{none/global//global/global}
\abx@aux@cite{falcon2019pytorch}
\abx@aux@segm{0}{0}{falcon2019pytorch}
\babel@aux{english}{}
\newlabel{sec:int}{{1}{1}{Introduction}{section.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction }{1}{section.1}\protected@file@percent }
\newlabel{sec:aut}{{2}{1}{Autencoder}{section.2}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {2}Autencoder }{1}{section.2}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Methods}{1}{subsection.2.1}\protected@file@percent }
\abx@aux@cite{optuna_2019}
\abx@aux@segm{0}{0}{optuna_2019}
\abx@aux@cite{fong2020marginal}
\abx@aux@segm{0}{0}{fong2020marginal}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Architecture of the Encoder structure of the Autoencoder.\relax }}{2}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:enc_arch}{{1}{2}{Architecture of the Encoder structure of the Autoencoder.\relax }{figure.caption.1}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Architecture of the Decoder structure of the Autoencoder.\relax }}{2}{figure.caption.1}\protected@file@percent }
\newlabel{fig:dec_arch}{{2}{2}{Architecture of the Decoder structure of the Autoencoder.\relax }{figure.caption.1}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Results}{2}{subsection.2.2}\protected@file@percent }
\newlabel{sec:den}{{3}{3}{Denoiser}{section.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {3}Denoiser }{3}{section.3}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Methods}{3}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Results}{3}{subsection.3.2}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces We present the original image, the noisy image and the denoised one for different samples of the test set. The results are really good, even though one of the digit is not denoised in the correct way, since it is almost impossible to understand which digit is represented in the noisy image for a human.\relax }}{3}{figure.caption.2}\protected@file@percent }
\newlabel{fig:noise}{{3}{3}{We present the original image, the noisy image and the denoised one for different samples of the test set. The results are really good, even though one of the digit is not denoised in the correct way, since it is almost impossible to understand which digit is represented in the noisy image for a human.\relax }{figure.caption.2}{}}
\newlabel{sec:ft}{{4}{3}{Fine Tuning}{section.4}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {4}Fine Tuning }{3}{section.4}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Methods}{3}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Results}{4}{subsection.4.2}\protected@file@percent }
\newlabel{sec:vae}{{5}{4}{Variational Autoencoders}{section.5}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {5}Variational Autoencoders }{4}{section.5}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Methods}{4}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Results}{4}{subsection.5.2}\protected@file@percent }
\newlabel{sec:enc}{{6}{4}{Encoded Space Analysis}{section.6}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {6}Encoded Space Analysis }{4}{section.6}\protected@file@percent }
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Methods}{4}{subsection.6.1}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Smooth evolution of the digit $6$ by varying the $0$-th component of its encoded representation by $1/5$ of its original value in each of the figures. The images should be read from left to right, starting from the top row. We notice that the digit changes smoothly from $6$ to $3$.\relax }}{5}{figure.caption.3}\protected@file@percent }
\newlabel{fig:smooth}{{4}{5}{Smooth evolution of the digit $6$ by varying the $0$-th component of its encoded representation by $1/5$ of its original value in each of the figures. The images should be read from left to right, starting from the top row. We notice that the digit changes smoothly from $6$ to $3$.\relax }{figure.caption.3}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Results}{5}{subsection.6.2}\protected@file@percent }
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Average absolute value of the difference between the standard deviation along the first encoded variable and the second one, looking at both the Autoencoder and the VAE, for PCA and t-SNE.\relax }}{5}{table.caption.4}\protected@file@percent }
\newlabel{tab:diff}{{1}{5}{Average absolute value of the difference between the standard deviation along the first encoded variable and the second one, looking at both the Autoencoder and the VAE, for PCA and t-SNE.\relax }{table.caption.4}{}}
\abx@aux@refcontextdefaultsdone
\abx@aux@defaultrefcontext{0}{falcon2019pytorch}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{optuna_2019}{none/global//global/global}
\abx@aux@defaultrefcontext{0}{fong2020marginal}{none/global//global/global}
\newlabel{sec:app}{{7}{7}{Appendix}{section.7}{}}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\contentsline {section}{\numberline {7}Appendix }{7}{section.7}\protected@file@percent }
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Optimization trend of the validation loss. On the y-axis we report the final validation loss, while on the x-axis the trial number. The red line represents the evolution of the best score.\relax }}{7}{figure.caption.6}\protected@file@percent }
\newlabel{fig:opt}{{5}{7}{Optimization trend of the validation loss. On the y-axis we report the final validation loss, while on the x-axis the trial number. The red line represents the evolution of the best score.\relax }{figure.caption.6}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Evolution of the validation loss. While some trial is pruned at the beginning for a poor performance we can observe that the validation loss converges quite quickly.\relax }}{7}{figure.caption.7}\protected@file@percent }
\newlabel{fig:losses}{{6}{7}{Evolution of the validation loss. While some trial is pruned at the beginning for a poor performance we can observe that the validation loss converges quite quickly.\relax }{figure.caption.7}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Visual representation of the used hyperparameters, where the color of the line connecting the parameters used in a single trial is related to the validation loss as shown in the colorbar. We can observe that the stochastic gradient descent is not performing well.\relax }}{8}{figure.caption.8}\protected@file@percent }
\newlabel{fig:hyper}{{7}{8}{Visual representation of the used hyperparameters, where the color of the line connecting the parameters used in a single trial is related to the validation loss as shown in the colorbar. We can observe that the stochastic gradient descent is not performing well.\relax }{figure.caption.8}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Reconstruction of the Autoencoder with optimized hyperparameters\relax }}{8}{figure.caption.9}\protected@file@percent }
\newlabel{fig:rec}{{8}{8}{Reconstruction of the Autoencoder with optimized hyperparameters\relax }{figure.caption.9}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Encoded space with dimensionality reduced with PCA for the classical Autoencoder, using as points the test set.\relax }}{8}{figure.caption.10}\protected@file@percent }
\newlabel{fig:aut_PCA}{{9}{8}{Encoded space with dimensionality reduced with PCA for the classical Autoencoder, using as points the test set.\relax }{figure.caption.10}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Encoded space with dimensionality reduced with PCA for the classical Autoencoder, using as points the test set.\relax }}{9}{figure.caption.11}\protected@file@percent }
\newlabel{fig:aut_TSNE}{{10}{9}{Encoded space with dimensionality reduced with PCA for the classical Autoencoder, using as points the test set.\relax }{figure.caption.11}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Encoded space with dimensionality reduction for the classical autoencoder, where the center of the ellipse is the average position of a given digit, while the ellipse represents its standard deviation along the two different coordinates.\relax }}{9}{figure.caption.12}\protected@file@percent }
\newlabel{fig:dim_red_aut}{{11}{9}{Encoded space with dimensionality reduction for the classical autoencoder, where the center of the ellipse is the average position of a given digit, while the ellipse represents its standard deviation along the two different coordinates.\relax }{figure.caption.12}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Encoded space with dimensionality reduced with PCA for the Variational Autoencoder, using as points the test set.\relax }}{9}{figure.caption.13}\protected@file@percent }
\newlabel{fig:vae_PCA}{{12}{9}{Encoded space with dimensionality reduced with PCA for the Variational Autoencoder, using as points the test set.\relax }{figure.caption.13}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Encoded space with dimensionality reduced with PCA for the Variational Autoencoder, using as points the test set.\relax }}{10}{figure.caption.14}\protected@file@percent }
\newlabel{fig:vae_TSNE}{{13}{10}{Encoded space with dimensionality reduced with PCA for the Variational Autoencoder, using as points the test set.\relax }{figure.caption.14}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Encoded space with dimensionality reduction for the Variational autoencoder, where the center of the ellipse is the average position of a given digit, while the ellipse represents its standard deviation along the two different coordinates.\relax }}{10}{figure.caption.15}\protected@file@percent }
\newlabel{fig:dim_red_vae}{{14}{10}{Encoded space with dimensionality reduction for the Variational autoencoder, where the center of the ellipse is the average position of a given digit, while the ellipse represents its standard deviation along the two different coordinates.\relax }{figure.caption.15}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Images generated by sampling the classical autencoder using a normal ditribution.\relax }}{10}{figure.caption.16}\protected@file@percent }
\newlabel{fig:gen_aut}{{15}{10}{Images generated by sampling the classical autencoder using a normal ditribution.\relax }{figure.caption.16}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Images generated by sampling the variational autencoder using a normal ditribution.\relax }}{10}{figure.caption.16}\protected@file@percent }
\newlabel{fig:gen_vae}{{16}{10}{Images generated by sampling the variational autencoder using a normal ditribution.\relax }{figure.caption.16}{}}
\gdef \@abspage@last{10}
